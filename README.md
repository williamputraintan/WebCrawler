# WebCrawler

The project simulates on how web search engine works on web by following every link on the web. They use sophisticated algorithms to search efficiently. For example, they don't follow each link equally often; content that changes often is followed more often.
<br><br>
This project will demonstrate crawl a web site that implement socket programming, which is fundamental to writing all internet applications, and also about the HTTP application layer protocol.

## Program Execution
To execute the program:
1. clone this repository and use linux terminal and makefile to compile the program with the cmd: *make*
1. Run the program with the execution name crawler followed by the url. Example : *crawler http://web1.comp30023*
